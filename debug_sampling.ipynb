{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import hydra\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import wandb\n",
    "from algos import build_algo\n",
    "from datasets import build_loader\n",
    "from htransform.likelihoods import get_likelihood\n",
    "from models import build_model\n",
    "from models.classifier_guidance_model import ClassifierGuidanceModel, HTransformModel\n",
    "from models.diffusion import Diffusion\n",
    "from utils.degredations import get_degreadation_image\n",
    "from utils.distributed import common_init, get_logger, init_processes\n",
    "from utils.functions import get_timesteps, postprocess, preprocess, strfdt\n",
    "from utils.save import save_result\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "initialize(version_base=\"1.2\", config_path=\"_configs\") \n",
    "cfg = compose(config_name=\"deft\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.exp\n",
    "cfg.exp.name = \"sr4_deft\"\n",
    "cfg.exp.samples_root = \"samples_trial\"\n",
    "cfg.exp.save_deg = True \n",
    "cfg.exp.save_evolution = False\n",
    "cfg.exp.save_ori = True\n",
    "cfg.exp.seed = 3\n",
    "cfg.exp.smoke_test = -1\n",
    "cfg.htransform_model.in_channels = 9\n",
    "cfg.htransform_model.num_channels = 64\n",
    "cfg.htransform_model.num_head_channels = 16\n",
    "cfg.htransform_model.out_channels = 3\n",
    "cfg.likelihood.forward_op.noise_std = 0.0\n",
    "cfg.likelihood.forward_op.scale = 4.0\n",
    "cfg.loader.batch_size = 10\n",
    "cfg.dist.num_processes_per_node = 1\n",
    "cfg.htransform_model.ckpt_path = \"/home/sp2058/DEFT/outputs/model_ckpts/sr4_deft_8fi2wuj3/model.pt\"\n",
    "\n",
    "cfg.wandb_config.log = False\n",
    "cfg.exp.name = \"debug_sampling\"\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg.cwd = \"/home/sp2058/DEFT/outputs/2024-10-24/08-18-53\"\n",
    "OmegaConf.set_struct(cfg, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.exp.seed 3\n",
      "Experiment name is debug_sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 20:27:30,101][model][INFO] - Loading model from pretrained_model/256x256_diffusion_uncond.pt..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp2058/DEFT/models/__init__.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_ckpt, map_location=map_location))\n",
      "/home/sp2058/DEFT/models/__init__.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  htransform_model.load_state_dict(torch.load(cfg.htransform_model.ckpt_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size is 1000\n",
      "Finetune dataset size is 1000\n",
      "Validation dataset size is 100\n",
      "{'name': 'deft', 'deg': 'sr4', 'finetune_args': {'batch_size': 100, 'shuffle': True, 'drop_last': True, 'epochs': 100, 'lr': 0.001, 'log_freq': 10, 'save_model_every_n_epoch': 10, 'lr_annealing': True}, 'val_args': {'batch_size': 10, 'psnr_batch_size': 100, 'num_steps': 100, 'eta': 0.0, 'use_ema': False, 'sample_freq': 5, 'psnr_sample_freq': -1}, 'ema': {'beta': 0.999, 'update_after_step': 400, 'update_every': 10}, 'use_x0hat': True, 'use_loggrad': True}\n",
      "deg sr4\n",
      "number of parameters in pretrained model:  552814086\n",
      "number of parameters in finetuned model:  23701700\n",
      "Fraction:  0.042874631092522486\n",
      "/home/sp2058/DEFT/outputs/model_ckpts/sr4_deft_8fi2wuj3/model.pt\n"
     ]
    }
   ],
   "source": [
    "# Initialize distributed process group\n",
    "try:\n",
    "    dist.init_process_group(\n",
    "        backend='nccl',\n",
    "        init_method='tcp://127.0.0.1:23456',\n",
    "        world_size=1,\n",
    "        rank=0\n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"cfg.exp.seed\", cfg.exp.seed)\n",
    "common_init(0, seed=cfg.exp.seed)\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "exp_name = cfg.exp.name\n",
    "print(f\"Experiment name is {exp_name}\")\n",
    "exp_root = cfg.exp.root\n",
    "samples_root = cfg.exp.samples_root\n",
    "samples_root = os.path.join(exp_root, samples_root, exp_name)\n",
    "\n",
    "dataset_name = cfg.dataset.name\n",
    "\n",
    "model, classifier, htransform_model = build_model(cfg)\n",
    "model.eval()\n",
    "\n",
    "if classifier is not None:\n",
    "    classifier.eval()\n",
    "loader = build_loader(cfg)\n",
    "\n",
    "print(f\"Dataset size is {len(loader.dataset)}\")\n",
    "\n",
    "diffusion = Diffusion(**cfg.diffusion)\n",
    "\n",
    "if \"deft\" in cfg.algo.name:\n",
    "    likelihood = get_likelihood(cfg, device=model.device)\n",
    "\n",
    "    cg_model = HTransformModel(\n",
    "        model, htransform_model, classifier, diffusion, likelihood, cfg\n",
    "    )\n",
    "else:\n",
    "    cg_model = ClassifierGuidanceModel(model, classifier, diffusion, cfg)\n",
    "\n",
    "algo = build_algo(cg_model, cfg)\n",
    "\n",
    "if (\n",
    "    \"ddrm\" in cfg.algo.name\n",
    "    or \"mcg\" in cfg.algo.name\n",
    "    or \"dps\" in cfg.algo.name\n",
    "    or \"pgdm\" in cfg.algo.name\n",
    "    or \"reddiff\" in cfg.algo.name\n",
    "    or \"deft\" in cfg.algo.name\n",
    "):\n",
    "    H = algo.H\n",
    "\n",
    "########################## DO FINETUNING IF NEEDED ##########\n",
    "print(cfg.htransform_model.ckpt_path)\n",
    "if cfg.algo.name == \"deft\" and cfg.htransform_model.ckpt_path is None:\n",
    "    algo.train()\n",
    "\n",
    "########################## DO EVAL ##########################\n",
    "psnrs = []\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g2dl72r9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-serenity-31</strong> at: <a href='https://wandb.ai/shreyaspadhy/deft/runs/g2dl72r9' target=\"_blank\">https://wandb.ai/shreyaspadhy/deft/runs/g2dl72r9</a><br/> View project at: <a href='https://wandb.ai/shreyaspadhy/deft' target=\"_blank\">https://wandb.ai/shreyaspadhy/deft</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241127_202748-g2dl72r9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:g2dl72r9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sp2058/DEFT/wandb/run-20241127_203154-9ss9sfqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shreyaspadhy/deft/runs/9ss9sfqe' target=\"_blank\">fallen-oath-32</a></strong> to <a href='https://wandb.ai/shreyaspadhy/deft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shreyaspadhy/deft' target=\"_blank\">https://wandb.ai/shreyaspadhy/deft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shreyaspadhy/deft/runs/9ss9sfqe' target=\"_blank\">https://wandb.ai/shreyaspadhy/deft/runs/9ss9sfqe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling w/ point estimate model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:33<00:00,  3.02it/s]\n",
      "0it [00:33, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "wandb.init()\n",
    "for it, (x, y, info) in tqdm(enumerate(loader)):\n",
    "    if cfg.exp.smoke_test > 0 and it >= cfg.exp.smoke_test:\n",
    "        break\n",
    "    # Images are in [0, 1]\n",
    "    # y here is the label of imagenet that class_cond models occasionally need.\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "\n",
    "    # Convert from [0, 1] to [-1, 1]\n",
    "    x = preprocess(x)\n",
    "    ts = get_timesteps(cfg)\n",
    "\n",
    "    kwargs = info\n",
    "    # TODO: Can we combine the likelihood forward pass for all algorithms?\n",
    "    if (\n",
    "        \"ddrm\" in cfg.algo.name\n",
    "        or \"mcg\" in cfg.algo.name\n",
    "        or \"dps\" in cfg.algo.name\n",
    "        or \"pgdm\" in cfg.algo.name\n",
    "        or \"reddiff\" in cfg.algo.name\n",
    "    ):\n",
    "        idx = info[\"index\"]\n",
    "        if \"inp\" in cfg.algo.deg or \"in2\" in cfg.algo.deg:  # what is in2?\n",
    "            H.set_indices(idx)\n",
    "        y_0 = H.H(x)\n",
    "\n",
    "        # This is to account for scaling to [-1, 1]\n",
    "        # y_0 is the degradation that we consider\n",
    "        y_0 = (\n",
    "            y_0 + torch.randn_like(y_0) * cfg.algo.sigma_y * 2\n",
    "        )  # ?? what is it for???\n",
    "        kwargs[\"y_0\"] = y_0\n",
    "    elif \"deft\" in cfg.algo.name:\n",
    "        # TODO: Use algo.sigma_y instead of forward_op.noise_std\n",
    "        # TODO: remove likelihood configs entirely, specify in algo.deg_args.\n",
    "        if \"inp\" in cfg.algo.deg or \"in2\" in cfg.algo.deg:\n",
    "            y_0, masks = algo.model.likelihood.sample(\n",
    "                x,\n",
    "                deterministic_idx=torch.arange(0, x.shape[0])\n",
    "                .long()\n",
    "                .to(algo.device),\n",
    "            )\n",
    "        else:\n",
    "            y_0 = algo.model.likelihood.sample(x)\n",
    "            masks = None\n",
    "        kwargs[\"masks\"] = masks\n",
    "        kwargs[\"y_0\"] = y_0\n",
    "        kwargs[\"use_ema\"] = cfg.algo.val_args.use_ema\n",
    "\n",
    "    # pgdm\n",
    "    if cfg.exp.save_evolution:\n",
    "        if cfg.algo.name == \"deft\":\n",
    "            raise NotImplementedError(\"DEFT does not support evolution saving\")\n",
    "        xt_s, _, xt_vis, _, mu_fft_abs_s, mu_fft_ang_s = algo.sample(\n",
    "            x, y, ts, **kwargs\n",
    "        )\n",
    "    else:\n",
    "        xt_s, _ = algo.sample(x, y, ts, **kwargs)\n",
    "    \n",
    "    # Save x, y, ts, kwargs\n",
    "    # Save sampling inputs for debugging\n",
    "    torch.save({\n",
    "        'x': x,\n",
    "        'y': y, \n",
    "        'ts': ts,\n",
    "        'kwargs': kwargs\n",
    "    }, 'sampling_inputs.pt')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(xt_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../adapt-diffusions\")\n",
    "from htransform.eval import calculate_total_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts:  [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 900, 910, 920, 930, 940, 950, 960, 970, 980, 990]\n",
      "{'batch_size': 10, 'num_steps': 100, 'eta': 1.0, 'sample_freq': 1, 'psnr_sample_freq': 1, 'psnr_batch_size': 10, 'rescale_image': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_xi_condition() got an unexpected keyword argument 'cfg_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 48\u001b[0m\n\u001b[1;32m     35\u001b[0m cfg_model \u001b[38;5;241m=\u001b[39m dict2namespace(finetune_model_cfg)\n\u001b[1;32m     38\u001b[0m val_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrescale_image\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m }\n\u001b[0;32m---> 48\u001b[0m \u001b[43mcalculate_total_psnr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtransform_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_target_score_matching\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrial\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DEFT/../adapt-diffusions/htransform/eval.py:260\u001b[0m, in \u001b[0;36mcalculate_total_psnr\u001b[0;34m(pretrained_score, finetuned_score, likelihood, val_dataloader, diffusion, device, val_kwargs, cfg_model, use_target_score_matching, save_images, save_path, image_path, smpl_type, log_dir)\u001b[0m\n\u001b[1;32m    254\u001b[0m guidance_model \u001b[38;5;241m=\u001b[39m ClassifierGuidanceModel(\n\u001b[1;32m    255\u001b[0m     model\u001b[38;5;241m=\u001b[39mcombined_model, classifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, diffusion\u001b[38;5;241m=\u001b[39mdiffusion, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m sampler \u001b[38;5;241m=\u001b[39m DDIM(model\u001b[38;5;241m=\u001b[39mguidance_model, cfg\u001b[38;5;241m=\u001b[39mconf)\n\u001b[0;32m--> 260\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m sample \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# First ensure all images in roughly [0, 1] instead of [-1, 1] for the PSNR function\u001b[39;00m\n",
      "File \u001b[0;32m~/DEFT/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DEFT/algos/ddim.py:48\u001b[0m, in \u001b[0;36mDDIM.sample\u001b[0;34m(self, x, y, ts, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# print(\"t in model : \", t)\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m et, x0_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m xs \u001b[38;5;241m=\u001b[39m alpha_s\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m x0_pred \u001b[38;5;241m+\u001b[39m c1 \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(xt) \u001b[38;5;241m+\u001b[39m c2 \u001b[38;5;241m*\u001b[39m et\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# xt_s.append(xs.cpu())\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# x0_s.append(x0_pred.cpu())\u001b[39;00m\n",
      "File \u001b[0;32m~/DEFT/models/classifier_guidance_model.py:28\u001b[0m, in \u001b[0;36mClassifierGuidanceModel.__call__\u001b[0;34m(self, xt, y, t, scale)\u001b[0m\n\u001b[1;32m     26\u001b[0m alpha_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion\u001b[38;5;241m.\u001b[39malpha(t)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     et \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m[:, :\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     et \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(xt, t, y)[:, :\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/DEFT/../adapt-diffusions/htransform/eval.py:240\u001b[0m, in \u001b[0;36mcalculate_total_psnr.<locals>.combined_model\u001b[0;34m(x, t)\u001b[0m\n\u001b[1;32m    236\u001b[0m alpha_t \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39malpha(t)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    238\u001b[0m x0hat \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m eps1 \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_t)\u001b[38;5;241m.\u001b[39msqrt()) \u001b[38;5;241m/\u001b[39m alpha_t\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[0;32m--> 240\u001b[0m xi_condition \u001b[38;5;241m=\u001b[39m \u001b[43mget_xi_condition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0hat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0hat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m eps2 \u001b[38;5;241m=\u001b[39m finetuned_score(xi_condition, t)\n\u001b[1;32m    250\u001b[0m eps \u001b[38;5;241m=\u001b[39m eps1 \u001b[38;5;241m+\u001b[39m eps2\n",
      "\u001b[0;31mTypeError\u001b[0m: get_xi_condition() got an unexpected keyword argument 'cfg_model'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "def dict2namespace(config):\n",
    "    namespace = argparse.Namespace()\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            new_value = dict2namespace(value)\n",
    "        else:\n",
    "            new_value = value\n",
    "        setattr(namespace, key, new_value)\n",
    "    return namespace\n",
    "\n",
    "finetune_model_cfg = {\n",
    "    \"attention_resolutions\": \"32,16,8\",\n",
    "    \"class_cond\": False,\n",
    "    \"dropout\": 0.0,\n",
    "    \"image_size\": 256,\n",
    "    \"learn_sigma\": True,\n",
    "    \"num_channels\": 256,\n",
    "    \"num_head_channels\": 64,\n",
    "    \"num_res_blocks\": 2,\n",
    "    \"resblock_updown\": True,\n",
    "    \"use_fp16\": False,\n",
    "    \"use_scale_shift_norm\": True,\n",
    "    \"num_heads\": 4,\n",
    "    \"num_heads_upsample\": -1,\n",
    "    \"conv_resample\": True,\n",
    "    \"dims\": 2,\n",
    "    \"num_classes\": None,\n",
    "    \"use_checkpoint\": False,\n",
    "    \"use_new_attention_order\": False,\n",
    "    \"num_samples\": 1\n",
    "}\n",
    "\n",
    "cfg_model = dict2namespace(finetune_model_cfg)\n",
    "\n",
    "\n",
    "val_kwargs={\n",
    "    \"batch_size\": 10,\n",
    "    \"num_steps\": 100,\n",
    "    \"eta\": 1.,\n",
    "    \"sample_freq\": 1,\n",
    "    \"psnr_sample_freq\": 1,\n",
    "    \"psnr_batch_size\": 10,\n",
    "    \"rescale_image\": True,\n",
    "}\n",
    "\n",
    "calculate_total_psnr(\n",
    "    algo.model.model,\n",
    "    algo.model.htransform_model,\n",
    "    algo.model.likelihood,\n",
    "    loader,\n",
    "    algo.model.diffusion,\n",
    "    algo.device,\n",
    "    val_kwargs,\n",
    "    cfg_model,\n",
    "    use_target_score_matching=False,\n",
    "    log_dir=\"trial\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "im1 = mpimg.imread('/home/sp2058/adapt-diffusions/test/n01440764/ILSVRC2012_val_00000293.png')\n",
    "im2 = mpimg.imread('/home/sp2058/adapt-diffusions/save_log/sr_htransform_kdbbaeqk/n01440764/ILSVRC2012_val_00000293.png')\n",
    "\n",
    "im3 = mpimg.imread('/home/sp2058/DEFT/outputs/samples/old_ckpt_new_sampling/n01440764/ILSVRC2012_val_00000293.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
